{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll go over word and sentence embeddings. We'll use the pre-trained GloVe embeddings model to get the embeddings for different phrases, and compare the embeddings for different sentences and visualize them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from scipy import spatial\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['tree']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to write a function to get the embedding vector for a sentence. We can use the model to get the embedding vector for each word, or token, in the sentence. For now, let's obtain the sentence embedding by naively taking the average of each word embedding in the sentence. This is a very naive approach (think about why) but will suffice for the purposes of this notebook. In practice, you would use an encoder neural network to derive sentence embeddings.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that gets the embedding vector for a sentence/phrase by taking the average of the word embedding vectors\n",
    "def get_embedding(sentence, model=model):\n",
    "    # Set all words to lowercase (the model only has lowercase words!), and tokenize it into words\n",
    "    # Also, remove punctuation\n",
    "    # Get the word embeddings for each word\n",
    "    # Return the average of the word embeddings\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings are just vectors in an embedding space, where the distance between the vectors reflect semantic similarity. If we write a function to calculate the distance between two vectors, we can evaluate the similarity between two sentences using their embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common ways to find the distance between two vectors include Euclidean Distance, Cosine Similarity, and the Dot Product. Pick any one of these three and implement them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use cosine similarity. It is probably the most common metric for comparing two vectors.\n",
    "# The cosine similarity of two vectors is the cosine of the angle between them.\n",
    "# Cosine similarity = 1 - cosine distance\n",
    "def calculate_distance(sentence1, sentence2, model=model):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between 'I took my dog to the park' and 'cats in nature' is: None\n"
     ]
    }
   ],
   "source": [
    "# Example words\n",
    "sentence1 = \"I took my dog to the park\"\n",
    "sentence2 = \"cats in nature\"\n",
    "\n",
    "# Calculate distance between embeddings\n",
    "distance = calculate_distance(sentence1, sentence2, model)\n",
    "print(f\"The distance between '{sentence1}' and '{sentence2}' is: {distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"I took my dog to the park\"\n",
    "sentence2 = \"Cats in nature\"\n",
    "\n",
    "embedding1 = get_embedding(sentence1, model)\n",
    "embedding2 = get_embedding(sentence2, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of embedding: (50,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dimension of embedding: {embedding1.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embeddings are very high dimension vectors. To be able to visualize them, we want to reduce their dimensionality. One common way to do this is [principal component analysis](https://en.wikipedia.org/wiki/Principal_component_analysis), or PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_with_similarity(sentences, model):\n",
    "    embeddings = np.array([get_embedding(sentence, model) for sentence in sentences])\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1])\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        plt.text(reduced_embeddings[i, 0], reduced_embeddings[i, 1], sentence)\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.title('Sentence Embeddings Visualization with PCA')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "sentences = [\"I took my dog to the park\", \n",
    "             \"Cats in nature\", \n",
    "             \"I love ice cream\", \n",
    "             \"Learning japanese sucks\",\n",
    "             \"naval warfare in the pacific\"\n",
    "            ]\n",
    "visualize_embeddings_with_similarity(sentences, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visual we've generated makes sense, but the lack of dimensions leaves much to be desired. Let's try this again, but with 3 dimensions. That should lead to more convincing visualizations of the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_with_similarity_3d(sentences, model):\n",
    "    embeddings = np.array([get_embedding(sentence, model) for sentence in sentences])\n",
    "\n",
    "    # Apply PCA with 3 components\n",
    "    pca = PCA(n_components=3)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], reduced_embeddings[:, 2])\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        ax.text(reduced_embeddings[i, 0], reduced_embeddings[i, 1], reduced_embeddings[i, 2], sentence)\n",
    "    ax.set_xlabel('PCA Component 1')\n",
    "    ax.set_ylabel('PCA Component 2')\n",
    "    ax.set_zlabel('PCA Component 3')\n",
    "    plt.title('Sentence Embeddings Visualization with PCA (3D)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embeddings_with_similarity_3d(sentences, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization of the embedding vectors in 3 dimensions more accurately distinguishes the meaning of the sentences from one another. The more dimensions we have, the more accurately and precisely we can discriminate between the meaning of different sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to challenge yourself, implement the dimensionality reduction again, this time using [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding), another common dimensionality reduction method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL CHALLENGE: Try to implement the same visualization but with t-SNE\n",
    "\n",
    "def visualize_embeddings_with_similarity_3d(sentences, model):\n",
    "    embeddings = np.array([get_embedding(sentence, model) for sentence in sentences])\n",
    "\n",
    "    # Apply t-SNE\n",
    "    tsne = TSNE(n_components=3, perplexity=len(embeddings)/4, metric='cosine')\n",
    "    reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], reduced_embeddings[:, 2])\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        ax.text(reduced_embeddings[i, 0], reduced_embeddings[i, 1], reduced_embeddings[i, 2], sentence)\n",
    "    \n",
    "    plt.title('Sentence Embeddings Visualization with t-SNE (3D)')\n",
    "    plt.show()\n",
    "\n",
    "visualize_embeddings_with_similarity_3d(sentences, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
