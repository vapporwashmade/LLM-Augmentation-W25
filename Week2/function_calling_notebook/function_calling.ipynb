{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====================================\n",
    "# Jupyter Notebook: Function Calling 101\n",
    "# ====================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scenario:\n",
    "    We have 4 functions:\n",
    "      1. get_weather_info(city)\n",
    "      2. book_flight(loc_origin, loc_destination, datetime, airline)\n",
    "      3. extract_entities\n",
    "      4. tag text\n",
    "\n",
    "We present them to the OpenAI model with 'function_descriptions'.\n",
    "When the user asks a question that matches the function usage, \n",
    "the model will produce a structured function call (JSON) with name & arguments.\n",
    "\n",
    "We'll manually parse the result from the model, call our Python function, \n",
    "and then feed that result back to the model to produce a final user-facing answer.\n",
    "\n",
    "TODO:\n",
    "  - Add more interesting scenarios (like file_complaint).\n",
    "  - Experiment with 'function_call=\"auto\"' vs. forced or required.\n",
    "  - Combine multiple user requests into a single prompt to see if the model calls \n",
    "    multiple functions or just one.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "########################################################\n",
    "# Section 1: Setup\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We'll use environment variables to store API keys.\n",
    "Make sure you have an OPENAI_API_KEY environment variable set.\n",
    "\"\"\"\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import openai\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"OpenAI Key Found:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "\n",
    "\n",
    "MODEL_NAME = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------\n",
    "# 2) Define Python functions to be \"called\"\n",
    "# -------------------------------------------------\n",
    "In this cell, we define the **actual** Python functions the model can “call.”  \n",
    "- `get_weather_info(city)`: Returns mocked weather data (in real usage, you'd call an actual weather API).  \n",
    "- `book_flight(...)`: Pretends to book a flight and returns a JSON-formatted confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_info(city: str):\n",
    "    \"\"\"\n",
    "    Dummy function that returns made-up weather data.\n",
    "    In reality, you'd call a weather API (like OpenWeatherMap).\n",
    "    \"\"\"\n",
    "    fake_data = {\n",
    "        \"Amsterdam\": {\"temp\": 15, \"condition\": \"Drizzle\"},\n",
    "        \"New York\": {\"temp\": 22, \"condition\": \"Sunny\"},\n",
    "        \"Paris\": {\"temp\": 16, \"condition\": \"Overcast\"}\n",
    "    }\n",
    "    weather = fake_data.get(city, {\"temp\": 0, \"condition\": \"Unknown\"})\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"city\": city,\n",
    "        \"temperature_c\": weather[\"temp\"],\n",
    "        \"conditions\": weather[\"condition\"]\n",
    "    })\n",
    "\n",
    "def book_flight(loc_origin: str, loc_destination: str, datetime_str: str, airline: str):\n",
    "    \"\"\"\n",
    "    Dummy function to 'book' a flight.\n",
    "    In reality, you'd integrate with an airline or travel booking API.\n",
    "    \"\"\"\n",
    "    return json.dumps({\n",
    "        \"status\": \"success\",\n",
    "        \"origin\": loc_origin,\n",
    "        \"destination\": loc_destination,\n",
    "        \"datetime\": datetime_str,\n",
    "        \"airline\": airline,\n",
    "        \"confirmation_number\": \"ABC123XYZ\"\n",
    "    })\n",
    "\n",
    "def extract_entities(text: str):\n",
    "    \"\"\"\n",
    "    Dummy function that 'extracts' person names and ages from text.\n",
    "    We'll simulate the result as a simple dictionary.\n",
    "    In reality, you'd do more sophisticated NER or rely on LLM logic directly.\n",
    "    \"\"\"\n",
    "    # Very naive \"parser\"\n",
    "    # If it sees \"Joe is 30\" => we store that as an entity\n",
    "    entities = []\n",
    "    words = text.split()\n",
    "    for i, w in enumerate(words):\n",
    "        if w.lower() in [\"joe\", \"mary\", \"bob\"]:\n",
    "            # check if next words might be \"is <age>\"\n",
    "            if i+2 < len(words) and words[i+1].lower() in [\"is\"] and words[i+2].isdigit():\n",
    "                entities.append({\"name\": w.capitalize(), \"age\": int(words[i+2])})\n",
    "            else:\n",
    "                entities.append({\"name\": w.capitalize(), \"age\": None})\n",
    "    return json.dumps({\"entities\": entities})\n",
    "\n",
    "def tag_text(text: str):\n",
    "    \"\"\"\n",
    "    Dummy function for tagging text with sentiment + language.\n",
    "    In reality, you'd call a sentiment classifier or language detection library.\n",
    "    \"\"\"\n",
    "    # We'll simulate some trivial checks:\n",
    "    sentiment = \"neutral\"\n",
    "    if any(x in text.lower() for x in [\"love\", \"great\", \"amazing\"]):\n",
    "        sentiment = \"pos\"\n",
    "    elif any(x in text.lower() for x in [\"hate\", \"terrible\", \"bad\", \"dislike\"]):\n",
    "        sentiment = \"neg\"\n",
    "\n",
    "    # We'll do a naive language detection check for 'mi piace' => italian\n",
    "    language = \"en\"\n",
    "    if \"mi piace\" in text.lower():\n",
    "        language = \"it\"\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"sentiment\": sentiment,\n",
    "        \"language\": language\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# -------------------------------------------------\n",
    "# 3) Describe these functions for OpenAI\n",
    "# -------------------------------------------------\n",
    "This cell simply displays all the functions (or “tools”) we’ve defined. We assign each function a name, description, and a JSON schema for its arguments, so the model knows how to call them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of function descriptions for API calls\n",
    "function_descriptions = [\n",
    "    {\n",
    "        \"type\": \"function\",  # Defines this as a function tool\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather_info\",  # Function name used by the LLM\n",
    "            \"description\": \"Retrieve current weather information for a city.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",  # Function expects an object as input\n",
    "                \"properties\": {\n",
    "                    \"city\": {\n",
    "                        \"type\": \"string\",  # City name as input\n",
    "                        \"description\": \"City to retrieve weather data for, e.g., 'Amsterdam'.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city\"]  # City is mandatory\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"book_flight\",\n",
    "            \"description\": \"Book a flight between two locations with a preferred airline.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"loc_origin\": {  \n",
    "                        \"type\": \"string\",  # Departure location\n",
    "                        \"description\": \"3-letter airport code or city name of departure.\"\n",
    "                    },\n",
    "                    \"loc_destination\": {\n",
    "                        \"type\": \"string\",  # Arrival location\n",
    "                        \"description\": \"3-letter airport code or city name of arrival.\"\n",
    "                    },\n",
    "                    \"datetime\": {\n",
    "                        \"type\": \"string\",  # Date/Time in ISO format\n",
    "                        \"description\": \"Flight date/time in ISO format, e.g., '2024-06-01 08:00'.\"\n",
    "                    },\n",
    "                    \"airline\": {\n",
    "                        \"type\": \"string\",  # Airline preference\n",
    "                        \"description\": \"Preferred airline for booking.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"loc_origin\", \"loc_destination\", \"datetime\", \"airline\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"extract_entities\",\n",
    "            \"description\": \"Extract named entities (e.g., person name, age) from text.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"text\": {\n",
    "                        \"type\": \"string\",  # Input text containing entities\n",
    "                        \"description\": \"Text to analyze for named entity recognition (NER).\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"text\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"tag_text\",\n",
    "            \"description\": \"Analyze text and tag it with sentiment and language.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"text\": {\n",
    "                        \"type\": \"string\",  # Input text to be classified\n",
    "                        \"description\": \"Text to be tagged with sentiment and language classification.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"text\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Function descriptions loaded.\")  # Confirmation message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Define and Document the Function `test_call_model`\n",
    "\n",
    "In this cell, we create a helper function named `test_call_model`. It:\n",
    "1. Accepts a user prompt (`user_message`) and a `function_call` mode (`\"auto\"`, `\"none\"`, or `{\"name\": \"...function_name...\"}`).\n",
    "2. Calls the OpenAI API with our **function (tool) descriptions** so the model knows which functions are available.\n",
    "3. Returns the model's raw response, which may include a function call if it decides that is relevant.\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "\n",
    " -------------------------------------------------\n",
    " Quick test with 'get_weather_info'\n",
    " -------------------------------------------------\n",
    " Purpose: \n",
    " Test if the model calls the \"get_weather_info\" function \n",
    " when we ask about the weather in Amsterdam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We'll pass our function schema to the model. The model can decide\n",
    "to call one function, multiple, or none, depending on user input.\n",
    "\n",
    "- function_call=\"auto\" => The model decides if/when to call.\n",
    "- function_call=\"none\" => The model cannot call any function.\n",
    "- function_call={\"name\":\"book_flight\"} => Force it to call 'book_flight'.\n",
    "\n",
    "Try toggling these below in the 'test_call_model' function.\n",
    "\"\"\"\n",
    "\n",
    "def test_call_model(user_message: str, function_call=\"auto\"):\n",
    "    \"\"\"\n",
    "    1) We send user_message + function_descriptions to the model\n",
    "    2) We see if it returns a function call\n",
    "    3) If so, we parse arguments, call the function ourselves\n",
    "    4) Return final output\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI()\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_message}],\n",
    "        tools=function_descriptions,  # 'functions' is now called 'tools'\n",
    "        tool_choice=function_call,    # 'function_call' is now 'tool_choice'\n",
    "    )\n",
    "    response = completion.choices[0].message\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Test with `get_weather_info`**\n",
    "Here, we try a simple user prompt asking about the weather in Amsterdam.  \n",
    "- We use `function_call=\"auto\"` so the model may decide to invoke our `get_weather_info` function if it deems it relevant.  \n",
    "- The cell prints out the raw model response so we can see if it includes a function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a quick test with something that calls 'get_weather_info'\n",
    "user_prompt_1 = \"What is the weather in Amsterdam?\"\n",
    "resp = test_call_model(user_prompt_1, function_call=\"auto\")\n",
    "print(\"Model response:\\n\", resp)\n",
    "print(\"\\nWe expect a 'function_call' to get_weather_info.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------\n",
    "# 5) Parse the response and call the function\n",
    "# -------------------------------------------------\n",
    "\n",
    " -------------------------------------------------\n",
    " Why This Code is Useful:\n",
    " Many LLM-based apps need to handle model outputs that\n",
    " specify a \"function call.\" This code acts as a \"bridge\":\n",
    " - If the LLM wants to invoke a function (to fetch data or\n",
    "   perform an action), we parse the model's tool_call info,\n",
    "   call the real Python function, and then use another API\n",
    "   call to produce a final, user-facing answer.\n",
    " - This approach is crucial for letting LLMs integrate\n",
    "   with external systems (e.g., weather APIs, booking\n",
    "   services) in a controlled, structured manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI()\n",
    "\n",
    "def handle_function_call(response) -> str:\n",
    "    \"\"\"\n",
    "    If the response contains a function call, execute it, return the result,\n",
    "    and pass it back to the model for a final answer.\n",
    "    \"\"\"\n",
    "    # If there's no function call, return the assistant's response as normal\n",
    "    if response.content and not hasattr(response, \"tool_calls\"):\n",
    "        return response.content\n",
    "\n",
    "    # Extract function call information\n",
    "    tool_calls = response.tool_calls\n",
    "    if not tool_calls:\n",
    "        return response.content\n",
    "\n",
    "    # Process the first function call in the list\n",
    "    tool_call = tool_calls[0]\n",
    "    fn_name = tool_call.function.name\n",
    "    fn_args = json.loads(tool_call.function.arguments)\n",
    "    tool_call_id = tool_call.id  # Extract tool_call_id\n",
    "    print(f\"Model wants to call function {fn_name} with args {fn_args}\")\n",
    "\n",
    "    # Route to the correct function\n",
    "    if fn_name == \"get_weather_info\":\n",
    "        city_req = fn_args[\"city\"]\n",
    "        function_result = get_weather_info(city_req)\n",
    "\n",
    "    elif fn_name == \"book_flight\":\n",
    "        loc_origin = fn_args[\"loc_origin\"]\n",
    "        loc_dest = fn_args[\"loc_destination\"]\n",
    "        dt = fn_args[\"datetime\"]\n",
    "        airline = fn_args[\"airline\"]\n",
    "        function_result = book_flight(loc_origin, loc_dest, dt, airline)\n",
    "    elif fn_name == \"extract_entities\":\n",
    "        text = fn_args[\"text\"]\n",
    "        function_result = extract_entities(text)\n",
    "    elif fn_name == \"tag_text\":\n",
    "        text = fn_args[\"text\"]\n",
    "        function_result = tag_text(text)\n",
    "    else:\n",
    "        return \"Function not recognized\"\n",
    "\n",
    "    # Ensure function_result is a string\n",
    "    function_result = str(function_result)\n",
    "\n",
    "    # Handle possible None content\n",
    "    previous_content = f\"Previously: {response.content}\" if response.content else \"Processing function call...\"\n",
    "\n",
    "    # Make a second model request, providing the function result\n",
    "    # so it can finalize a user-facing response. \n",
    "    # This step is commonly used to incorporate the function's data\n",
    "    # (e.g., \"temp=15C, partly cloudy\") into a full natural language\n",
    "    # answer for the end user.\n",
    "    second_response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": previous_content},  \n",
    "            {\"role\": \"assistant\", \"tool_calls\": response.tool_calls},  # Include the original tool call\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call_id,\n",
    "                \"name\": fn_name,\n",
    "                \"content\": function_result\n",
    "            }  \n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Extract final answer\n",
    "    final_answer = second_response.choices[0].message.content\n",
    "    return final_answer\n",
    "\n",
    "# Test it end-to-end\n",
    "final_text = handle_function_call(resp)\n",
    "print(\"\\nFinal text back to user:\\n\", final_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------\n",
    "# 6) Another Example: Book a flight\n",
    "# -------------------------------------------------\n",
    " Why This Is Useful:\n",
    " Demonstrates how a user request can trigger the \"book_flight\" function.\n",
    " This pattern can generalize to many use cases like \"place an order\",\n",
    " \"schedule a meeting\", etc. The LLM decides the best function to call\n",
    " and we do the behind-the-scenes work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We'll ask a multi-part question that might trigger the model to call the second function.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_2 = \"I want to book a flight from AMS to JFK on 2024-06-02 at 10:00 with Delta Airlines\"\n",
    "resp2 = test_call_model(user_prompt_2, function_call=\"auto\")\n",
    "print(\"Model response:\\n\", resp2)\n",
    "\n",
    "final_text_2 = handle_function_call(resp2)\n",
    "print(\"\\nUser-Facing Answer:\\n\", final_text_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------\n",
    "# 7)  Section: Entity Extraction\n",
    "# -------------------------------------------------\n",
    " Why This Is Useful:\n",
    " Shows how the LLM can parse unstructured text (e.g., \"Joe is 30,\n",
    " Mary is older...\") and call a function that extracts relevant entities\n",
    " or structured data. This is a building block for advanced data extraction,\n",
    " knowledge-base population, or record creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We have an 'extract_entities' function that looks for simple name/age pairs.\n",
    "Let's see if the LLM picks that function for a user query describing people.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_3 = \"Joe is 30, Mary is older but we don't know her age.\"\n",
    "resp3 = test_call_model(user_prompt_3, function_call=\"auto\")\n",
    "print(\"\\n=== Entity Extraction Test ===\")\n",
    "print(\"Model response:\\n\", resp3)\n",
    "final_text_3 = handle_function_call(resp3)\n",
    "print(\"\\nUser-Facing Answer:\\n\", final_text_3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------\n",
    "# 8) Section: Tagging\n",
    "# -------------------------------------------------\n",
    " Why This Is Useful:\n",
    " Tagging or classification can be critical for sentiment analysis,\n",
    " content moderation, or language detection. By letting the LLM call\n",
    " a specialized \"tag_text\" function, you can unify your external logic\n",
    " (like a custom sentiment model) with the language reasoning of the LLM.\n",
    "\n",
    " (Implementation of the function or usage example would go here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We have a 'tag_text' function that returns a naive sentiment & language.\n",
    "We'll see if the model calls it automatically if the user requests tagging.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_4 = \"Can you tag this text for me: 'mi piace la pizza, it's amazing!'\"\n",
    "resp4 = test_call_model(user_prompt_4, function_call=\"auto\")\n",
    "print(\"\\n=== Tagging Test ===\")\n",
    "print(\"Model response:\\n\", resp4)\n",
    "final_text_4 = handle_function_call(resp4)\n",
    "print(\"\\nUser-Facing Answer:\\n\", final_text_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------\n",
    "# 9) Activity / Optional Challenge\n",
    "# -------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1) Try combining the two tasks into one user request:\n",
    "   e.g. \"What's the weather in New York, \n",
    "         and also please book me a flight from LAX to SFO next Friday at 9am with United.\"\n",
    "\n",
    "   Observe if the model tries to call multiple functions or just one. \n",
    "   Because the standard function calling only returns ONE call at a time, \n",
    "   you might get partial coverage. \n",
    "   (HINT: you'll need to loop to handle multiple calls or do more advanced logic.)\n",
    "\n",
    "2) Create a third function, e.g. \"file_complaint(name, email, text)\", \n",
    "   to simulate a user wanting to file a complaint about their flight.\n",
    "   Add that to function_descriptions, \n",
    "   then see if the model picks it up when the user says \n",
    "   \"I want to file a complaint about my missed flight. My name is Jane, email is jane@example.com\"\n",
    "\n",
    "3) Experiment with forcing a function call:\n",
    "   - function_call=\"none\": The model won't produce any function calls.\n",
    "   - function_call={\"name\":\"book_flight\"}: The model *must* call the 'book_flight' function, \n",
    "     which might lead to it guessing arguments if the user didn't specify them.\n",
    "\n",
    "4) If you want an advanced challenge, \n",
    "   handle repeated calls automatically:\n",
    "   - If the model calls one function, you feed the result, \n",
    "     then it calls a second function, etc.\n",
    "   - This is sometimes referred to as a \"multi-step\" or \"agentic\" approach.\n",
    "\n",
    "Have fun and experiment!\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------\n",
    "# 10) End\n",
    "# -------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
